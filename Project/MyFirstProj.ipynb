{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe goal of this experiment is to develop a model that will predict (to a certain level of acceptable accuracy) the students final GPAs, given the current progress.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The goal of this experiment is to develop a model that will predict (to a certain level of acceptable accuracy) the students final GPAs, given the current progress.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# courses = [['ten_gpa', 'twelth_gpa', 'colz_gpa', 'nimcet_marks'], \n",
    "#            ['psqt_gpa', 'me_gpa', 'co_gpa', 'pscp_gpa', 'pscp_lab_gpa', 'foss_lab_gpa'], \n",
    "#            ['afm_gpa', 'ds_gpa', 'ss_gpa', 'oops_gpa', 'aad_gpa', 'ds_lab_gpa', 'ss_lab_gpa', 'oops_lab_gpa'], \n",
    "#            ['os_gpa', 'dbms_gpa', 'wt_gpa', 'ospm_gpa', 'ads_gpa', 'os_lab_gpa', 'dbms_lab_gpa', 'wt_lab_gpa'], \n",
    "#            ['pdwdm_gpa', 'ccn_gpa', 'se_gpa', 'ooad_gpa', 'dos_gpa', 'ke_lab_gpa', 'ccn_lab_gpa', 'set_lab_gpa'], \n",
    "#            ['nps_gpa', 'uc_gpa', 'cc_gpa', 'dpsa_gpa', 'stt_gpa', 'seminar_viva_gpa', 'nps_lab_gpa', 'stt_lab_gpa'], \n",
    "#            ['project_gpa']]\n",
    "\n",
    "# courses = ['psqt_gpa', 'me_gpa', 'co_gpa', 'pscp_gpa', 'pscp_lab_gpa', 'foss_lab_gpa', \n",
    "#            'afm_gpa', 'ds_gpa', 'ss_gpa', 'oops_gpa', 'aad_gpa', 'ds_lab_gpa', 'ss_lab_gpa', 'oops_lab_gpa', \n",
    "#            'os_gpa', 'dbms_gpa', 'wt_gpa', 'ospm_gpa', 'ads_gpa', 'os_lab_gpa', 'dbms_lab_gpa', 'wt_lab_gpa', \n",
    "#            'pdwdm_gpa', 'ccn_gpa', 'se_gpa', 'ooad_gpa', 'dos_gpa', 'ke_lab_gpa', 'ccn_lab_gpa', 'set_lab_gpa', \n",
    "#            'nps_gpa', 'uc_gpa', 'cc_gpa', 'dpsa_gpa', 'stt_gpa', 'seminar_viva_gpa', 'nps_lab_gpa', 'stt_lab_gpa', \n",
    "#            'project_gpa']\n",
    "\n",
    "# course_cluster = []\n",
    "# K = 5\n",
    "# for c in range(K):\n",
    "#     course_cluster.append([])\n",
    "\n",
    "\n",
    "\"\"\" Split Data into Training and Testing Sets \"\"\"\n",
    "def split_data(X, Y):\n",
    "    return train_test_split(X, Y, test_size=0.2, random_state=17)\n",
    "\n",
    "\"\"\" Extract feature (X) and target (y) columns \"\"\"\n",
    "def extract_features_and_target_cols(df, semester):\n",
    "    feature_cols = df\n",
    "    target_cols = df\n",
    "    \n",
    "    if(semester == 1):\n",
    "        feature_cols = list(df.columns[:4])  \n",
    "        target_cols = df.columns[5:11]\n",
    "    elif(semester == 2):\n",
    "        feature_cols = list(df.columns[:11])  \n",
    "        target_cols = df.columns[12:21]\n",
    "    elif(semester == 3):\n",
    "        feature_cols = list(df.columns[:21])  \n",
    "        target_cols = df.columns[22:31]\n",
    "    elif(semester == 4):\n",
    "        feature_cols = list(df.columns[:31])  \n",
    "        target_cols = df.columns[32:41]\n",
    "    elif(semester == 5):\n",
    "        feature_cols = list(df.columns[:41])  \n",
    "        target_cols = df.columns[42:51]\n",
    "    elif(semester == 6):\n",
    "        feature_cols = list(df.columns[:51])  \n",
    "        target_cols = df.columns[-2:] \n",
    "    return feature_cols, target_cols\n",
    "\n",
    "# def relevant_courses(clustered_courses, current_course):\n",
    "#     for cluster in clustered_courses:\n",
    "#         if current_course in str(cluster):\n",
    "#             return cluster\n",
    "\n",
    "# def predict_gpa(semester):\n",
    "#     print(courses)\n",
    "    \n",
    "# #     clustered_courses = \n",
    "    \n",
    "    \n",
    "#     num_of_courses = len(courses[semester])\n",
    "    \n",
    "#     for course in range(num_of_courses):\n",
    "#         current_course = courses[semester][course]\n",
    "#         relevant_courses = relevant_courses(clustered_courses, current_course)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\"\"\" kNN Algorithm for training and predicting the datasets \"\"\"\n",
    "def knn_train_and_predict(semester, df):\n",
    "    \"\"\"\n",
    "    To train and test accuracy using the kNN algorithm with the datasets\n",
    "    :param semester:\n",
    "    :param data frame:\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"KNN: \")\n",
    "    feature_cols, target_cols = extract_features_and_target_cols(df, semester)\n",
    "\n",
    "    print(feature_cols)\n",
    "    X = df[feature_cols]  # feature values for all students\n",
    "    y = df[target_cols]  # corresponding targets/labels\n",
    "#     print(\"\\nFeature values:-\")\n",
    "#     print(X.head())  # print the first 5 rows \n",
    "\n",
    "    x_train, x_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_x = StandardScaler()\n",
    "    x_train = sc_x.fit_transform(x_train)\n",
    "    x_test = sc_x.transform(x_test)\n",
    "    sc_y = StandardScaler()\n",
    "    y_train = sc_y.fit_transform(y_train)\n",
    "    y_test = sc_y.transform(y_test)\n",
    "    \n",
    "    # instantiate a kNN regression model, and fit with X and y\n",
    "    model = neighbors.KNeighborsRegressor()\n",
    "    model = model.fit(x_train, y_train)\n",
    "\n",
    "#     print(model.predict(X_test))\n",
    "    \n",
    "    # check the accuracy on the training set\n",
    "    confidence = model.score(x_test, y_test)\n",
    "    print('accuracy:',confidence)\n",
    "    \n",
    "    from sklearn.metrics import r2_score\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"r2 score: \", r2_score(y_test , y_pred))\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    accuracies = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracies.mean: \", accuracies.mean())\n",
    "    print(\"S.d.: \", accuracies.std())\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    print(\"mse: \", mse_test)\n",
    "\n",
    "def random_forest_train_and_predict(semester, df):\n",
    "    \"\"\"\n",
    "    To train and test accuracy using the random forest regressor with the datasets\n",
    "    :param semester:\n",
    "    :param data frame:\n",
    "    \"\"\"\n",
    "    print(\"\\n\\nRandom Forest: \")\n",
    "    feature_cols, target_cols = extract_features_and_target_cols(df, semester)\n",
    "    target_cols = df.columns[-1:]\n",
    "   \n",
    "\n",
    "    X = df[feature_cols]  # feature values for all students\n",
    "    y = df[target_cols]  # corresponding targets/labels\n",
    "    \n",
    "#     seed = 7\n",
    "#     num_trees = 100\n",
    "#     kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # instantiate a random forest model\n",
    "#     model = RandomForestRegressor(n_estimators=num_trees)\n",
    "#     results = model_selection.cross_val_score(model, X, y, cv=kfold)\n",
    "   \n",
    "    # check the accuracy on the training set\n",
    "#     print(\"accuracy:\", results.mean())\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_x = StandardScaler()\n",
    "    x_train = sc_x.fit_transform(x_train)\n",
    "    x_test = sc_x.transform(x_test)\n",
    "    sc_y = StandardScaler()\n",
    "#     print(y_train.head())\n",
    "    y_train = sc_y.fit_transform(y_train)\n",
    "    y_test = sc_y.transform(y_test)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    regressor = RandomForestRegressor(n_estimators = 100, random_state = 0, oob_score = True)\n",
    "    regressor.fit(x_train, np.ravel(y_train,order='C'))\n",
    "\n",
    "    \n",
    "    from sklearn.metrics import r2_score\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    print(\"r2 score: \", r2_score(y_test , y_pred))\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    print(\"mse: \", mse_test)\n",
    "#     print(\"y_pred: \\n\", y_pred)\n",
    "#     print(\"y_tst: \\n\", y_test)\n",
    "    \n",
    "#     print(X_train.shape)\n",
    "#     print(y_train.shape)\n",
    "#     model = RandomForestRegressor()\n",
    "#     model = model.fit(X_train, y_train)\n",
    "\n",
    "    # check the accuracy on the training set\n",
    "#     confidence = model.score(X_test, y_test)\n",
    "#     print('RF accuracy:',confidence)\n",
    "#     predictions = model.predict(X_test)\n",
    "#     print('predicted class counts:',Counter(predictions))\n",
    "    \n",
    "\n",
    "def logistic_regression_train_and_predict(semester, df):\n",
    "    \"\"\"\n",
    "    To train and test accuracy using the logistic regression with the datasets\n",
    "    :param semester:\n",
    "    :param data frame:\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Logistic Regression: \")\n",
    "    feature_cols, target_cols = extract_features_and_target_cols(df, semester)\n",
    "    \n",
    "    X = df[feature_cols]  # feature values for all students\n",
    "    y = df[target_cols]  # corresponding targets/labels\n",
    "    \n",
    "    scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=5)\n",
    "    print(scores)\n",
    "    print(\"Accuracy: \", scores.mean())\n",
    "        \n",
    "def linear_regression_train_and_predict(semester, df):\n",
    "    \"\"\"\n",
    "    To train and test accuracy using the linear regression with the datasets\n",
    "    :param semester:\n",
    "    :param data frame:\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\\nLinear Regression: \")\n",
    "    feature_cols, target_cols = extract_features_and_target_cols(df, semester)\n",
    "    \n",
    "    X = df[feature_cols]  # feature values for all students\n",
    "    y = df[target_cols]  # corresponding targets/labels\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_x = StandardScaler()\n",
    "    x_train = sc_x.fit_transform(x_train)\n",
    "    x_test = sc_x.transform(x_test)\n",
    "    sc_y = StandardScaler()\n",
    "    y_train = sc_y.fit_transform(y_train)\n",
    "    y_test = sc_y.transform(y_test)\n",
    "    \n",
    "    # Create linear regression object\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # check the accuracy on the training set\n",
    "    confidence = model.score(x_test, y_test)\n",
    "    print('accuracy:',confidence)\n",
    "    \n",
    "    from sklearn.metrics import r2_score\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"r2 score: \", r2_score(y_test , y_pred))\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    accuracies = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracies.mean: \", accuracies.mean())\n",
    "    print(\"S.d.: \", accuracies.std())\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    print(\"mse: \", mse_test)\n",
    "    \n",
    "# def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "#     Q = Q.T\n",
    "#     for step in range(steps):\n",
    "#         for i in range(len(R)):\n",
    "#             for j in range(len(R[i])):\n",
    "#                 if R[i][j] > 0:\n",
    "#                     eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "#                     for k in range(K):\n",
    "#                         P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "#                         Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "#         eR = np.dot(P,Q)\n",
    "#         e = 0\n",
    "#         for i in range(len(R)):\n",
    "#             for j in range(len(R[i])):\n",
    "#                 if R[i][j] > 0:\n",
    "#                     e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "#                     for k in range(K):\n",
    "#                         e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "#         if e < 0.001:\n",
    "#             break\n",
    "#     return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Random Forest: \n",
      "target cols:  Index(['cgpa_final'], dtype='object')\n",
      "r2 score:  0.9198286987438987\n",
      "mse:  0.06912116226522623\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Import helper libraries \"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "\n",
    "\"\"\" Read data file as DataFrame \"\"\"\n",
    "df = pd.read_csv(\"dataset.txt\", sep=\",\")\n",
    "\n",
    "# X = df.as_matrix()  #convert data frame to its equivalent matrix form\n",
    "\n",
    "# course_cluster_matrix = obtain_course_cluster_matrix(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sem = 6\n",
    "# predict_gpa(sem)\n",
    "# knn_train_and_predict(sem, df)\n",
    "random_forest_train_and_predict(sem, df)\n",
    "# logistic_regression_train_and_predict(sem, df)\n",
    "# linear_regression_train_and_predict(sem, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "[[], [], ['eng', 'bio', 'civics', 'history', 'chem'], ['math'], []]\n"
     ]
    }
   ],
   "source": [
    "X = [[5.42, 7.54, 7.04, 6.84, 6.0, 6.7 ],\n",
    "       [6.74, 7.96, 7.5 , 6.72, 6.0, 6.6 ],\n",
    "       [5.99, 5.29, 6.2 , 7.06, 6.0, 6.89],\n",
    "       [6.2 , 6.21, 5.86, 6.32, 6.0, 6.26],\n",
    "       [7.34, 6.98, 7.72, 6.99, 9.0, 7.33],\n",
    "       [7.72, 7.68, 7.24, 6.41, 7.0, 6.51]]\n",
    "\n",
    "courses = ['eng', 'math', 'bio', 'civics', 'history', 'chem']#'physics', 'hindi', 'geography', 'comp sc']\n",
    "\n",
    "course_cluster = obtain_course_cluster_matrix(X)\n",
    "\n",
    "print(course_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_course_cluster_matrix(X):\n",
    "    N = len(X)\n",
    "    M = len(X[0])\n",
    "\n",
    "    print(N, M)\n",
    "\n",
    "    K = 5\n",
    "\n",
    "    P = np.random.rand(N,K)\n",
    "    Q = np.random.rand(M,K)\n",
    "\n",
    "    U, V = matrix_factorization(X, P, Q, K)\n",
    "#     new_X = np.dot(U, V.T)\n",
    "\n",
    "        \n",
    "    for c in range(len(courses)):\n",
    "        cluster = 0\n",
    "        for curr in range(K):\n",
    "            if V[curr][c] >= cluster:\n",
    "                cluster = curr\n",
    "        course_cluster[cluster].append(courses[c])\n",
    "        \n",
    "    return course_cluster\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_c = [['y', 'h', 'u', 'o', 'i', 'e','a'], ['b', 'c', 'd', 'f', 'g', 'j', 'm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['y', 'h', 'u', 'o', 'i', 'e', 'a'], ['b', 'c', 'd', 'f', 'g', 'j', 'm']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
